for (i in 2:4){
beta_i <- lm_multb$coefficients[i]
sd_i <- summary(lm_multb)$coefficients[,2][i]
t <- qt(0.95, df=398)
IC <- c(beta_i-t*sd_i, beta_i+t*sd_i)
}
for (i in 2:4){
beta_i <- lm_multb$coefficients[i]
sd_i <- summary(lm_multb)$coefficients[,2][i]
t <- qt(0.95, df=398)
IC[i] <- c(beta_i-t*sd_i, beta_i+t*sd_i)
}
IC
for (i in 2:4){
beta_i <- lm_multb$coefficients[i]
sd_i <- summary(lm_multb)$coefficients[,2][i]
t <- qt(0.95, df=398)
c(beta_i-t*sd_i, beta_i+t*sd_i)
}
beta_1 <- lm_multb$coefficients[2]
sd_1 <- summary(lm_multb)$coefficients[,2][2]
t <- qt(0.95, df=398)
IC1 <- c(beta_1-t*sd_1, beta_1+t*sd_1)
help("confint")
confint(lm_multb, level=0.95)
beta_1 <- lm_multb$coefficients[2]
sd_1 <- summary(lm_multb)$coefficients[,2][2]
t <- qt(0.95, df=398)
IC1 <- c(beta_1-(t*sd_1), beta_1+(t*sd_1))
beta_1 <- lm_multb$coefficients[2]
sd_1 <- summary(lm_multb)$coefficients[,2][2]
t <- qt(0.95, df=395)
IC1 <- c(beta_1-(t*sd_1), beta_1+(t*sd_1))
beta_1 <- 0.010769
sd_1 <- 0.004042
t <- qt(0.95, df=395)
IC1 <- c(beta_1-(t*sd_1), beta_1+(t*sd_1))
confint(Carseats$Income, level=0.95)
beta_1 <- lm_multb$coefficients[2]
sd_1 <- summary(lm_multb)$coefficients[,2][2]
t <- qt(0.95, df=398)
IC1 <- c(beta_1-(t*sd_1), beta_1+(t*sd_1))
confint(lm_multb, level=0.9)
confint(lm_multb, level=0.95)
NutritionStudy <- read.delim("C:/Users/pilar/Downloads/NutritionStudy.txt")
View(NutritionStudy)
summary(lm_mult)
lm_mult <- lm(Calories ~ Fat + Cholesterol + Year, data=NutritionStudy)
lm_mult <- lm(Calories ~ Fat + Cholesterol + Age, data=NutritionStudy)
summary(lm_mult)
y_pred <- beta_0 + beta_1*40 + beta_2*180 + beta_3*35
beta_0 <- lm_multb$coefficients[1]
beta_1 <- lm_multb$coefficients[2]
beta_2 <- lm_multb$coefficients[3]
beta_3 <- lm_multb$coefficients[4]
y_pred <- beta_0 + beta_1*40 + beta_2*180 + beta_3*35
y_pred <- beta_0 + beta_1*35 + beta_2*40 + beta_3*180
y_pred <- beta_0 + beta_1*40 + beta_2*180 + beta_3*35
beta_3 <- lm_multb$coefficients[4]
beta_0 <- lm_multb$coefficients[1]
beta_1 <- lm_multb$coefficients[2]
beta_2 <- lm_multb$coefficients[3]
beta_3 <- lm_multb$coefficients[4]
lm_mult <- lm(Calories ~ Fat + Cholesterol + Age, data=NutritionStudy)
summary(lm_mult)
beta_0 <- lm_multb$coefficients[1]
beta_0 <- lm_mult$coefficients[1]
beta_1 <- lm_mult$coefficients[2]
beta_2 <- lm_mult$coefficients[3]
beta_3 <- lm_mult$coefficients[4]
y_pred <- beta_0 + beta_1*40 + beta_2*180 + beta_3*35
y_pred <- beta_0 + beta_1*40 + beta_2*180 + beta_3*35
y5 <- NutritionStudy$Calories[5]
y5_pred <- beta_0 + beta_1*NutritionStudy$Fat[5] + beta_2*NutritionStudy$Cholesterol[5] + beta_3*NutritionStudy$Age[5]
res5 <- y5_pred-y5
res5 <- y5-y5_pred
lm_mult$residuals[5]
RSS <- sum((lm_mult$residuals)^2)
TSS <- var(NutritionStudy$Calories)*(315-1)
R2 <- (TSS-RSS)/TSS
confint(lm_mult, level=0.95)
ajuste_log <- glm(defecto ~ temp, data = challenger, family = binomial(link=logit))
#4
defectos <- sum(challenger$defecto == 1)
challenger <- read.csv("C:/Users/pilar/Downloads/challenger.txt", sep="")
View(challenger)
ajuste_log <- glm(defecto ~ temp, data = challenger, family = binomial(link=logit))
summary(rl)
source("~/Di Tella/A3S1/Inferencia/guia6.R", echo=TRUE)
summary(ajuste_log)
ajuste_log <- glm(defecto ~ temp, data = challenger, family = binomial)
summary(ajuste_log)
summary(ajuste_log)
temp_new <- seq(min(challenger$temp), max(challenger$temp), 0.01)
data_new <- data.frame(temp = temp_new)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
plot(challenger$temp, challenger$defecto, xlab = "temp", ylab = "def")
lines(data_new, default_fit, col = "red")
lines(challenger$temp, default_fit, col = "red")
length(default_fit)
length(challenger$temp)
temp_new <- seq(min(challenger$temp), max(challenger$temp), 0.01)
help("seq")
temp_new <- seq(min(challenger$temp), max(challenger$temp))
temp_new <- seq(min(challenger$temp), max(challenger$temp))
data_new <- data.frame(temp = temp_new)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
plot(challenger$temp, challenger$defecto, xlab = "temp", ylab = "def")
lines(data_new, default_fit, col = "red")
temp_new <- seq(min(challenger$temp), max(challenger$temp), 1)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
lines(data_new, default_fit, col = "red")
length(data_new)
data_new <- data.frame(temp = temp_new)
View(data_new)
lines(data_new$temp, default_fit, col = "red")
length(data_new)
length(data_new$temp)
temp_new <- seq(50, 85, 1)
data_new <- data.frame(temp = temp_new)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
plot(challenger$temp, challenger$defecto, xlab = "temp", ylab = "def")
lines(data_new$temp, default_fit, col = "red")
help(predict)
y73 <- predict(ajuste_log,73, type='response')
y73 <- predict(ajuste_log,challenger$temp == 73, type='response')
15.04-0.232*73
y73 <- predict(ajuste_log,c(0,73), type='response')
y73 <- predict(ajuste_log,73, type='response')
plot(challenger$temp, challenger$defecto, xlab = "temp", ylab = "def")
lines(data_new$temp, default_fit, col = "red")
predict(ajuste_log,newdata = data.frame(temp=73), type = "response")
?Carseats
lm_mult <- lm(Sales ~ Income + Advertising + Price + Population + Age, data=Carseats)
lm_mult <- lm(Sales ~ Income + Advertising + Price + Population + Age, data=Carseats)
library(ISLR2)
?Carseats
lm_mult <- lm(Sales ~ Income + Advertising + Price + Population + Age, data=Carseats)
summary(lm_mult)
lm_multb <- lm(Sales ~ Income + Advertising + Price + Age, data=Carseats)
summary(lm_multb)
beta_1 <- lm_multb$coefficients[2]
sd_1 <- summary(lm_multb)$coefficients[,2][2]
t <- qt(0.95, df=398)
IC1 <- c(beta_1-(t*sd_1), beta_1+(t*sd_1))
confint(lm_multb, level=0.95)
IC1 <- c(beta_1-(t*sd_1), beta_1+(t*sd_1))
beta_1 <- lm_multb$coefficients[1]
sd_1 <- summary(lm_multb)$coefficients[,1][1]
t <- qt(0.95, df=398)
IC1 <- c(beta_1-(t*sd_1), beta_1+(t*sd_1))
IC1 <- c(beta_1-(t*sd_1), beta_1+(t*sd_1))
lm_multb <- lm(Sales ~ Income + Advertising + Price + Age, data=Carseats)
summary(lm_multb)
beta_1 <- lm_multb$coefficients[1]
beta_1 <- lm_multb$coefficients[2]
sd_1 <- summary(lm_multb)$coefficients[,2][2]
#qt(1-alfa/2, df)
t <- qt(0.975, df=398)
IC1 <- c(beta_1-(t*sd_1), beta_1+(t*sd_1))
help(qt)
help(pt)
help(pn)
help(qnorm)
2*(1-pnorm(4.023))
help(confint)
choque <- read.csv("C:/Users/pilar/Downloads/choque.txt", sep="")
View(choque)
#7
plot(vel,choque, data = choque)
#7
plot(choque$vel,choque$choca, pch=19)
boxplot(choque$choca ~ choque$vel)
boxplot(choque$vel ~ choque$choca)
ajuste_log <- glm(choque$choca ~ choque$vel, family=binomial)
summary(ajuste_log)
summary(ajuste_lin)
ajuste_lin <- lm(choque$choca ~ choque$vel)
summary(ajuste_lin)
summary(ajuste_log)
vel_new <- seq(min(choque$vel), max(choque$vel), 1)
data_new <- data.frame(vel = vel_new)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
plot(choque$vel, choque$choca, xlab = "temp", ylab = "def")
lines(data_new$vel, default_fit, col = "red")
plot(choque$vel, choque$choca, xlab = "temp", ylab = "def", pch=19)
length(data_new$vel)
vel_new <- seq(0, 100, 1)
data_new <- data.frame(vel = vel_new)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
plot(choque$vel, choque$choca, xlab = "temp", ylab = "def", pch=19)
lines(data_new$vel, default_fit, col = "red")
vel_new <- seq(min(choque$vel), max(choque$vel), 0.01)
vel_new <- seq(min(choque$vel), max(choque$vel), 1)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
#temp_new <- seq(min(challenger$temp), max(challenger$temp), 1)
temp_new <- seq(50, 85, 1)
data_new <- data.frame(temp = temp_new)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
vel_new <- seq(min(choque$vel), max(choque$vel), 1)
data_new <- data.frame(vel = vel_new)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
plot(choque$vel, choque$choca, xlab = "temp", ylab = "def", pch=19)
lines(data_new$vel, default_fit, col = "red")
ajuste_log <- glm(defecto ~ temp, data = challenger, family = binomial)
temp_new <- seq(50, 85, 1)
data_new <- data.frame(temp = temp_new)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
plot(challenger$temp, challenger$defecto, xlab = "temp", ylab = "def")
lines(data_new$temp, default_fit, col = "red")
ajuste_log <- glm(choque$choca ~ choque$vel, family=binomial)
summary(ajuste_log)
vel_new <- seq(min(choque$vel), max(choque$vel), 1)
data_new <- data.frame(vel = vel_new)
View(data_new)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
help("predict")
plot(choque$vel, choque$choca, xlab = "vel", ylab = "choca", pch=19)
lines(data_new$vel, default_fit, col = "red")
View(data_new)
lines(default_fit,data_new$vel,col = "red")
ajuste_log <- glm(defecto ~ temp, data = challenger, family = binomial)
#temp_new <- seq(min(challenger$temp), max(challenger$temp), 1)
temp_new <- seq(50, 85, 1)
data_new <- data.frame(temp = temp_new)
default_fit <- predict(ajuste_log, newdata = data_new, type = "response")
plot(challenger$temp, challenger$defecto, xlab = "temp", ylab = "def")
lines(data_new$temp, default_fit, col = "red")
length(data_new$temp)
length(default_fit)
ajuste_log <- glm(choca ~ vel, data = choque, family=binomial)
summary(ajuste_log)
vel_new <- seq(min(choque$vel), max(choque$vel), 1)
data_new <- data.frame(vel = vel_new)
default_fit <- predict(ajuste_log, newdata = data_new2, type = "response")
data_new2 <- data.frame(vel = vel_new)
default_fit <- predict(ajuste_log, newdata = data_new2, type = "response")
plot(choque$vel, choque$choca, xlab = "vel", ylab = "choca", pch=19)
lines(data_new$vel, default_fit, col = "red")
ajuste_log <- glm(choca ~ vel, data = choque, family=binomial)
summary(ajuste_log)
confint(ajuste_log, 0.9)
confint(ajuste_log, level = 0.9)
beta_1 <- ajuste_log$coefficients[1]
beta_1 <- ajuste_log$coefficients[2]
ajuste_log <- glm(choca ~ vel, data = choque, family=binomial)
summary(ajuste_log)
beta_1 <- ajuste_log$coefficients[2]
sd_1 <- ajuste_log$coefficients[2][2]
sd_1 <- summary(ajuste_log)$coefficients[,2][2]
z <- qnorm(1-(0.1)/2)
IC <- c(beta_1-z*sd_1,beta_1+z*sd_1)
confint(ajuste_log, level = 0.9)
help("t.test")
help(prop.test)
library(ISLR2)
#7
rectaregresion <- lm(Auto$mpg ~ Auto$horsepower)
summary(rectaregresion)
plot(Auto$horsepower, Auto$mpg)
t <- qt(1-0.01/2, df=390)
a <- beta1 - t*sd_beta1
b <- beta1 + t*sd_beta1
beta1 <- sum((Auto$horsepower-x_raya)*(Auto$mpg-y_raya))/sum((Auto$horsepower-x_raya)^2)
x_raya <- mean(Auto$horsepower)
y_raya <- mean(Auto$mpg)
beta1 <- sum((Auto$horsepower-x_raya)*(Auto$mpg-y_raya))/sum((Auto$horsepower-x_raya)^2)
sd_beta1 <- sqrt((RSE^2)/TSS)
t <- qt(1-0.01/2, df=390)
a <- beta1 - t*sd_beta1
b <- beta1 + t*sd_beta1
sd_beta1 <- sqrt((RSE^2)/TSS)
RSE <- sqrt(sum((rectaregresion$residuals)^2)*(1/(length(Auto$horsepower)-2)))
sd_beta1 <- sqrt((RSE^2)/TSS)
t <- qt(1-0.01/2, df=390)
a <- beta1 - t*sd_beta1
b <- beta1 + t*sd_beta1
IC <- c(a,b)
t <- qt(1-0.01/2, df=390)
a <- beta1 - t*sd_beta1
sd_beta1 <- 0.006446
a <- beta1 - t*sd_beta1
b <- beta1 + t*sd_beta1
TSS <- sum((Auto$horsepower - x_raya)^2)
TSS <- sum((Auto$horsepower - y_raya)^2)
TSS <- sum((Auto$mpg - y_raya)^2)
help("cor")
cor(Auto$horsepower, Auto$mpg)
abline(rectamc, col="red")
abline(rectaregresion, col="red")
summary(rectaregresion)
var(Auto$horsepower)
denom <- sum((Auto$horsepower - x_raya)^2)
var(Auto$horsepower)*391
help(pt)
pt(54.429, df=390)
pt(54.429, df=390)
pt(2.6259, df=100)
1-pt(2.6259, df=100)
(1-pt(2.6259, df=100))*2
# install.packages("rpart") # Descomentar si no lo tienen ya instalado.
library(rpart)
# install.packages("titanic") # Descomentar si no lo tienen ya instalado.
library(titanic)
train <- titanic_train
test <- titanic_test
str(train)
train$Pclass <- as.factor(train$Pclass)
train$Sex <- as.factor(train$Sex)
train$Pclass <- as.factor(train$Pclass)
train$Sex <- as.factor(train$Sex)
train$Pclass <- as.factor(train$Pclass)
train$Sex <- as.factor(train$Sex)
### **Datos**
Carguemos los datos que vamos a usar. Para este ejemplo, vamos a usar la base de datos `titanic`, que ya se encuentra cargada en R. (Usamos una base de datos similar sobre el Titanic en la P01, pero mediante un archivo CSV aparte).
# install.packages("rpart") # Descomentar si no lo tienen ya instalado.
library(rpart)
# install.packages("titanic") # Descomentar si no lo tienen ya instalado.
library(titanic)
train <- titanic_train
test <- titanic_test
str(train)
train$Pclass <- as.factor(train$Pclass)
train$Sex <- as.factor(train$Sex)
table(is.na(train))
summary(train)
set.seed(22)
tree <- rpart(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,
data = train,
method = "class")
# install.packages("rpart.plot") # Descomentar si no lo tienen ya instalado.
library(rpart.plot)
rpart.plot(tree)
test$Pclass <- as.factor(test$Pclass)
test$Sex <- as.factor(test$Sex)
predictions  <- predict(tree, newdata = test, type = "class")
train_withoutNA <- train
train_withoutNA$Age[is.na(train_withoutNA$Age)] <- mean(train_withoutNA$Age, na.rm = TRUE)
tree_withoutNA <- rpart(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,
data = train_withoutNA,
method = "class")
predictions_withoutNA <- predict(tree_withoutNA, newdata = test, type = "class")
data.frame("predicciones_con_na" = predictions,
"predicciones_sin_na" = predictions_withoutNA)
# Load the necessary libraries for data analysis and visualization
library(ggplot2)  # For creating plots
# Load necessary libraries
library(rpart)
library(Metrics)
library(caret)
install.package("rlang")
install.packages("rlang")
install.packages("rlang")
# Load necessary libraries
library(rpart)
library(Metrics)
library(caret)
# Load necessary libraries
library(rpart)
library(Metrics)
library(caret)
# Load necessary libraries
library(rpart)
library(Metrics)
library(caret)
install.packages("rlang")
install.packages("rlang")
# Load necessary libraries
library(rpart)
library(Metrics)
library(caret)
# Load the necessary libraries for data analysis and visualization
library(ggplot2)  # For creating plots
library(dplyr)    # For data manipulation
# Constants and global variables
PARALLELIZE <- TRUE # Set the option for parallelization of computations
N_THREADS <- 30     # Define the number of threads for parallel processing
N_BINS <- 10        # Define the number of bins for discretization
RERUN_EXP <- TRUE   # Set the option to rerun the experiment
# Load provided functions
source("provided_functions.R")
setwd("~/Di Tella/A3S2/TecnologiaVI/TDVI_tp1")
# Load the necessary libraries for data analysis and visualization
library(ggplot2)  # For creating plots
library(dplyr)    # For data manipulation
# Constants and global variables
PARALLELIZE <- TRUE # Set the option for parallelization of computations
N_THREADS <- 30     # Define the number of threads for parallel processing
N_BINS <- 10        # Define the number of bins for discretization
RERUN_EXP <- TRUE   # Set the option to rerun the experiment
# Load provided functions
source("provided_functions.R")
#Set seed
set.seed(006396374)
#' Run an experiment to evaluate the performance of a predictive model under different conditions.
#'
#' @param datasets_to_pred A list of data frames, each containing a dataset to be predicted.
#' @param filepath The path to the file where the experiment results will be saved.
#' @return None (the experiment results are saved to a file).
#'
#' @details
#' This function iterates through the given datasets, imputation methods, and proportions
#' of missing data. For each combination, it configures the preprocessing options, performs
#' the experiment, and stores the results in a list. The list of results is then combined into
#' a single data frame, which is saved to the specified file.
#'
run_experiment <- function(datasets_to_pred, filepath) {
exp_results <- list()  # Store experiment results
i <- 1  # Initialize counter for experiment results
# Iterate through different dataset, imputation, and proportion of missing values combinations
for (dtp in datasets_to_pred) {
for (impute in c("Yes","No")) {
for (prop_NAs in seq(0.1, 0.9, 0.2)){
for (prop_switch_y in seq(0, 0.5, 0.05)) {
print(c(dtp$dataset_name, impute, prop_NAs, prop_switch_y))
# Configure preprocessing options based on imputation choice
if (impute == "Yes") {
preprocess_control <- list(
prop_NAs=0,
impute_NAs=TRUE,
treat_NAs_as_new_levels=FALSE,
do_ohe=FALSE,
discretize=FALSE,
n_bins=N_BINS,
ord_to_numeric=FALSE,
prop_switch_y=prop_switch_y
)
} else if (impute == "No") {
preprocess_control <- list(
prop_NAs=0,
impute_NAs=FALSE,
treat_NAs_as_new_levels=FALSE,
do_ohe=FALSE,
discretize=FALSE,
n_bins=N_BINS,
ord_to_numeric=FALSE,
prop_switch_y=prop_switch_y
)
}
# Perform the experiment for the current settings
if (PARALLELIZE == TRUE) {
res_tmp <- est_auc_across_depths(dtp, preprocess_control,
max_maxdepth=30, prop_val=0.25,
val_reps=30)
} else {
res_tmp <- est_auc_across_depths_no_par(dtp, preprocess_control,
max_maxdepth=30, prop_val=0.25,
val_reps=30)
}
res_tmp$IMPUTED <- impute
res_tmp$prop_NAs <- prop_NAs
res_tmp$prop_switch_y <- prop_switch_y
exp_results[[i]] <- res_tmp
rm(res_tmp)  # Clean up temporary result
i <- i + 1  # Increment result counter
}
}
}
}
# Combine experiment results into a single data frame
exp_results <- do.call(rbind, exp_results)
# Save experiment results to a file
write.table(exp_results, filepath, row.names=FALSE, sep="\t")
}
#' Plot the results of the sample experiment using ggplot2.
#'
#' @param filename_exp_results The filename of the experiment results file.
#' @param filename_plot The filename to save the plot (e.g., "my_plot.png").
#' @param width The width of the plot in inches.
#' @param height The height of the plot in inches.
#' @return None (the plot is saved as an image file).
#'
#' @details
#' This function reads the experiment results, calculates the mean AUC values for different
#' experimental conditions, and generates a line plot using ggplot2. The plot displays the mean AUC
#' values against maximum tree depths, with different lines for different imputation methods and facets
#' for different datasets and proportions of missing data. The resulting plot is saved as the specified file.
#'
plot_exp_results <- function(filename_exp_results, filename_plot, width, height) {
# Load experiment results
exp_results <- read.table(filename_exp_results, header=TRUE, sep="\t")
# Calculate mean AUC values for different groups of experimental results
data_for_plot <- exp_results %>%
group_by(dataset_name, prop_NAs, prop_switch_y, IMPUTED, maxdepth) %>%
summarize(mean_auc=mean(auc), .groups='drop_last') %>%
summarize(max_auc=max(mean_auc), .groups='drop')
# Create a ggplot object for the line plot
g <- ggplot(data_for_plot, aes(x=prop_switch_y, y=max_auc, color=IMPUTED)) +
geom_line() +
theme_bw() +
xlab("Proportion of Y switched faceted by Proportion of NAs") +
ylab("max AUC (estimated through repeated validation)") +
facet_grid(dataset_name ~ prop_NAs, scales="free_y") +
theme(legend.position="bottom",
panel.grid.major=element_blank(),
strip.background=element_blank(),
panel.border=element_rect(colour="black", fill=NA))
# Save the plot to a file
ggsave(filename_plot, g, width=width, height=height)
}
# Load the datasets
datasets_to_pred <- list(
load_df("./data/CO2_Emissions_Transformado.csv", "CO2", "CO2.Emissions.g.km"),
#load_df("./data/heart.csv", "Heart", "HeartDisease"),
load_df("./data/customer_churn.csv", "Churn", "churn")
)
# Run the experiment
if (RERUN_EXP ==  TRUE) {
run_experiment(datasets_to_pred, "./outputs/tables/exp_propio.txt")
}
# Plot the experiment results
plot_exp_results( "./outputs/tables/exp_propio.txt", "./outputs/plots/exp_propio.jpg", width=15, height=8)
