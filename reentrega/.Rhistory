#' a single data frame, which is saved to the specified file.
#'
run_experiment <- function(datasets_to_pred, filepath) {
exp_results <- list()  # Store experiment results
i <- 1  # Initialize counter for experiment results
# Iterate through different dataset, imputation, and proportion of missing values combinations
for (dtp in datasets_to_pred) {
for (q in c(1,2,3,4)) {
for (noise_level in c(10,15,30)) {
print(c(dtp$dataset_name, q, noise_level))
# Configure preprocessing options based on imputation choice
preprocess_control <- list(
prop_NAs=0,
impute_NAs=FALSE,
treat_NAs_as_new_levels=FALSE,
do_ohe=FALSE,
discretize=FALSE,
n_bins=N_BINS,
ord_to_numeric=FALSE,
prop_switch_y=0,
prop_noise_x=1,
q_noisy_var=q,
dataset_actual=dtp$dataset_name,
noise_level=noise_level
)
# Perform the experiment for the current settings
if (PARALLELIZE == TRUE) {
res_tmp <- est_auc_across_depths(dtp, preprocess_control,
max_maxdepth=30, prop_val=0.25,
val_reps=30)
} else {
res_tmp <- est_auc_across_depths_no_par(dtp, preprocess_control,
max_maxdepth=30, prop_val=0.25,
val_reps=30)
}
res_tmp$q_noisy_var <- q
res_tmp$noise_level <- noise_level
exp_results[[i]] <- res_tmp
rm(res_tmp)  # Clean up temporary result
i <- i + 1  # Increment result counter
}
}
}
# Combine experiment results into a single data frame
exp_results <- do.call(rbind, exp_results)
# Save experiment results to a file
write.table(exp_results, filepath, row.names=FALSE, sep="\t")
}
#' Plot the results of the sample experiment using ggplot2.
#'
#' @param filename_exp_results The filename of the experiment results file.
#' @param filename_plot The filename to save the plot (e.g., "my_plot.png").
#' @param width The width of the plot in inches.
#' @param height The height of the plot in inches.
#' @return None (the plot is saved as an image file).
#'
#' @details
#' This function reads the experiment results, calculates the mean AUC values for different
#' experimental conditions, and generates a line plot using ggplot2. The plot displays the mean AUC
#' values against maximum tree depths, with different lines for different imputation methods and facets
#' for different datasets and proportions of missing data. The resulting plot is saved as the specified file.
#'
plot_exp_results <- function(filename_exp_results, filename_plot, width, height) {
# Load experiment results
exp_results <- read.table(filename_exp_results, header=TRUE, sep="\t")
exp_results$noise_level <- as.factor(exp_results$noise_level)
# Calculate max AUC values for different groups of experimental results
data_for_plot <- exp_results %>%
group_by(dataset_name, noise_level, q_noisy_var, maxdepth) %>%
summarize(mean_auc=mean(auc), .groups='drop')
# Create a ggplot object for the line plot
g <- ggplot(data_for_plot, aes(x=maxdepth, y=mean_auc, color=noise_level)) +
geom_line() +
theme_bw() +
ggtitle("Proportion of noisy X")+
xlab("Max tree depth") +
ylab("AUC (estimated through repeated validation)") +
facet_grid(dataset_name ~ q_noisy_var, scales="free_y") +
theme(legend.position="bottom",
panel.grid.major=element_blank(),
strip.background=element_blank(),
panel.border=element_rect(colour="black", fill=NA),
plot.title.position = 'plot',
plot.title = element_text(hjust=0.5, size=10))
# Save the plot to a file
ggsave(filename_plot, g, width=width, height=height)
print(g)
}
# Load the datasets
datasets_to_pred <- list(
load_df("./data/CO2_Emissions_Transformado.csv", "CO2", "CO2.Emissions.gt.200gkm"),
load_df("./data/heart.csv", "Heart", "HeartDisease"),
load_df("./data/customer_churn.csv", "Churn", "churn")
)
# Run the experiment
if (RERUN_EXP ==  TRUE) {
run_experiment(datasets_to_pred, "./outputs/tables/exp_propio.txt")
}
# Load the necessary libraries for data analysis and visualization
library(ggplot2)  # For creating plots
suppressPackageStartupMessages(library("dplyr"))  # For data manipulation
# Constants and global variables
PARALLELIZE <- TRUE # Set the option for parallelization of computations
N_THREADS <- 30     # Define the number of threads for parallel processing
N_BINS <- 10        # Define the number of bins for discretization
RERUN_EXP <- TRUE   # Set the option to rerun the experiment
# Load provided functions
source("provided_functions_reentrega.R")
#Set seed
set.seed(006396374)
#' Run an experiment to evaluate the performance of a predictive model under different conditions.
#'
#' @param datasets_to_pred A list of data frames, each containing a dataset to be predicted.
#' @param filepath The path to the file where the experiment results will be saved.
#' @return None (the experiment results are saved to a file).
#'
#' @details
#' This function iterates through the given datasets, imputation methods, and proportions
#' of missing data. For each combination, it configures the preprocessing options, performs
#' the experiment, and stores the results in a list. The list of results is then combined into
#' a single data frame, which is saved to the specified file.
#'
run_experiment <- function(datasets_to_pred, filepath) {
exp_results <- list()  # Store experiment results
i <- 1  # Initialize counter for experiment results
# Iterate through different dataset, imputation, and proportion of missing values combinations
for (dtp in datasets_to_pred) {
for (q in c(1,2,3,4)) {
for (noise_level in c(10,30)) {
print(c(dtp$dataset_name, q, noise_level))
# Configure preprocessing options based on imputation choice
preprocess_control <- list(
prop_NAs=0,
impute_NAs=FALSE,
treat_NAs_as_new_levels=FALSE,
do_ohe=FALSE,
discretize=FALSE,
n_bins=N_BINS,
ord_to_numeric=FALSE,
prop_switch_y=0,
prop_noise_x=1,
q_noisy_var=q,
dataset_actual=dtp$dataset_name,
noise_level=noise_level
)
# Perform the experiment for the current settings
if (PARALLELIZE == TRUE) {
res_tmp <- est_auc_across_depths(dtp, preprocess_control,
max_maxdepth=30, prop_val=0.25,
val_reps=30)
} else {
res_tmp <- est_auc_across_depths_no_par(dtp, preprocess_control,
max_maxdepth=30, prop_val=0.25,
val_reps=30)
}
res_tmp$q_noisy_var <- q
res_tmp$noise_level <- noise_level
exp_results[[i]] <- res_tmp
rm(res_tmp)  # Clean up temporary result
i <- i + 1  # Increment result counter
}
}
}
# Combine experiment results into a single data frame
exp_results <- do.call(rbind, exp_results)
# Save experiment results to a file
write.table(exp_results, filepath, row.names=FALSE, sep="\t")
}
#' Plot the results of the sample experiment using ggplot2.
#'
#' @param filename_exp_results The filename of the experiment results file.
#' @param filename_plot The filename to save the plot (e.g., "my_plot.png").
#' @param width The width of the plot in inches.
#' @param height The height of the plot in inches.
#' @return None (the plot is saved as an image file).
#'
#' @details
#' This function reads the experiment results, calculates the mean AUC values for different
#' experimental conditions, and generates a line plot using ggplot2. The plot displays the mean AUC
#' values against maximum tree depths, with different lines for different imputation methods and facets
#' for different datasets and proportions of missing data. The resulting plot is saved as the specified file.
#'
plot_exp_results <- function(filename_exp_results, filename_plot, width, height) {
# Load experiment results
exp_results <- read.table(filename_exp_results, header=TRUE, sep="\t")
exp_results$noise_level <- as.factor(exp_results$noise_level)
# Calculate max AUC values for different groups of experimental results
data_for_plot <- exp_results %>%
group_by(dataset_name, noise_level, q_noisy_var, maxdepth) %>%
summarize(mean_auc=mean(auc), .groups='drop')
# Create a ggplot object for the line plot
g <- ggplot(data_for_plot, aes(x=maxdepth, y=mean_auc, color=noise_level)) +
geom_line() +
theme_bw() +
ggtitle("Proportion of noisy X")+
xlab("Max tree depth") +
ylab("AUC (estimated through repeated validation)") +
facet_grid(dataset_name ~ q_noisy_var, scales="free_y") +
theme(legend.position="bottom",
panel.grid.major=element_blank(),
strip.background=element_blank(),
panel.border=element_rect(colour="black", fill=NA),
plot.title.position = 'plot',
plot.title = element_text(hjust=0.5, size=10))
# Save the plot to a file
ggsave(filename_plot, g, width=width, height=height)
print(g)
}
# Load the datasets
datasets_to_pred <- list(
load_df("./data/CO2_Emissions_Transformado.csv", "CO2", "CO2.Emissions.gt.200gkm"),
load_df("./data/heart.csv", "Heart", "HeartDisease"),
load_df("./data/customer_churn.csv", "Churn", "churn")
)
# Run the experiment
if (RERUN_EXP ==  TRUE) {
run_experiment(datasets_to_pred, "./outputs/tables/exp_propio.txt")
}
# Plot the experiment results
plot_exp_results( "./outputs/tables/exp_propio.txt", "./outputs/plots/exp_propio.jpg", width=15, height=8)
source("provided_functions_reentrega.R")
data <- load_df("./data/CO2_Emissions_Transformado.csv", "CO2", "CO2.Emissions.gt.200gkm")
data_df <- data$data_df
dataset_actual <- data$dataset_name
var_to_predict <- data$var_to_predict
prop_val <- 0.25
val_index <- sample(1:nrow(data_df), ceiling(nrow(data_df) * prop_val))
train_df <- data_df[-val_index,]
train_df_anterior <- data_df[-val_index,]
val_df <- data_df[val_index,]
if ("obs_id_value" %in% colnames(train_df)) {
stop("obs_id_value is already a variable name in the data")
}
train_df$obs_id_value <- 1:nrow(train_df)
val_df$obs_id_value <- 1:nrow(val_df)
X_train <- train_df[, setdiff(colnames(train_df), var_to_predict)]
y_train <- train_df[, c("obs_id_value", var_to_predict)]
X_val <- val_df[, setdiff(colnames(train_df), var_to_predict)]
y_val <- val_df[, c("obs_id_value", var_to_predict)]
rm(train_df, val_df)
prop_noise_x <- 1
noise_level <- 30
q_noisy_var <- 1
if (prop_noise_x > 0) {
num_rows_to_add_noise <- ceiling(nrow(X_train) * prop_noise_x)
noise_level <- noise_level
if (dataset_actual == "Heart"){
df <- read.csv("./data/heart.csv")
tree <- rpart(HeartDisease~., data = df, control=rpart.control(minsplit=2, minbucket=1, maxdepth=10, cp=0, xval=0))
importance_scores <- tree$variable.importance
top_variables <- names(importance_scores[order(-importance_scores)])[1:q_noisy_var]
}
for (var_name in top_variables) {
if (is.numeric(X_train[[var_name]])) {
noise <- rnorm(num_rows_to_add_noise, mean = 0, sd = noise_level * sd(X_train[[var_name]]))
X_train[sample(nrow(X_train), num_rows_to_add_noise), var_name] <- X_train[sample(nrow(X_train), num_rows_to_add_noise), var_name] + noise
} else {
var_to_switch <- var_name
unique_levels <- unique(X_train[[var_to_switch]])
for (i in seq_len(num_rows_to_add_noise)) {
random_row <- sample(seq_len(nrow(X_train)), 1)
current_value <- X_train[random_row, var_to_switch]
replacement_value <- sample(setdiff(unique_levels, current_value), 1)
X_train[random_row, var_to_switch] <- replacement_value
}
}
}
}
names(importance_scores[order(-importance_scores)])[1:q_noisy_var]
source("provided_functions_reentrega.R")
data <- load_df("./data/CO2_Emissions_Transformado.csv", "CO2", "CO2.Emissions.gt.200gkm")
data_df <- data$data_df
dataset_actual <- data$dataset_name
var_to_predict <- data$var_to_predict
prop_val <- 0.25
val_index <- sample(1:nrow(data_df), ceiling(nrow(data_df) * prop_val))
train_df <- data_df[-val_index,]
train_df_anterior <- data_df[-val_index,]
val_df <- data_df[val_index,]
if ("obs_id_value" %in% colnames(train_df)) {
stop("obs_id_value is already a variable name in the data")
}
train_df$obs_id_value <- 1:nrow(train_df)
val_df$obs_id_value <- 1:nrow(val_df)
X_train <- train_df[, setdiff(colnames(train_df), var_to_predict)]
y_train <- train_df[, c("obs_id_value", var_to_predict)]
X_val <- val_df[, setdiff(colnames(train_df), var_to_predict)]
y_val <- val_df[, c("obs_id_value", var_to_predict)]
rm(train_df, val_df)
prop_noise_x <- 1
noise_level <- 30
q_noisy_var <- 1
if (prop_noise_x > 0) {
num_rows_to_add_noise <- ceiling(nrow(X_train) * prop_noise_x)
noise_level <- noise_level
if (dataset_actual == "Heart"){
df <- read.csv("./data/heart.csv")
tree <- rpart(HeartDisease~., data = df, control=rpart.control(minsplit=2, minbucket=1, maxdepth=10, cp=0, xval=0))
importance_scores <- tree$variable.importance
top_variables <- names(importance_scores[order(-importance_scores)])[1:q_noisy_var]
}
for (var_name in top_variables) {
if (is.numeric(X_train[[var_name]])) {
noise <- rnorm(num_rows_to_add_noise, mean = 0, sd = noise_level * sd(X_train[[var_name]]))
X_train[sample(nrow(X_train), num_rows_to_add_noise), var_name] <- X_train[sample(nrow(X_train), num_rows_to_add_noise), var_name] + noise
} else {
var_to_switch <- var_name
unique_levels <- unique(X_train[[var_to_switch]])
for (i in seq_len(num_rows_to_add_noise)) {
random_row <- sample(seq_len(nrow(X_train)), 1)
current_value <- X_train[random_row, var_to_switch]
replacement_value <- sample(setdiff(unique_levels, current_value), 1)
X_train[random_row, var_to_switch] <- replacement_value
}
}
}
}
source("provided_functions_reentrega.R")
data <- load_df("./data/heart.csv", "Heart", "HeartDisease")
data_df <- data$data_df
dataset_actual <- data$dataset_name
var_to_predict <- data$var_to_predict
prop_val <- 0.25
val_index <- sample(1:nrow(data_df), ceiling(nrow(data_df) * prop_val))
train_df <- data_df[-val_index,]
train_df_anterior <- data_df[-val_index,]
val_df <- data_df[val_index,]
if ("obs_id_value" %in% colnames(train_df)) {
stop("obs_id_value is already a variable name in the data")
}
train_df$obs_id_value <- 1:nrow(train_df)
val_df$obs_id_value <- 1:nrow(val_df)
X_train <- train_df[, setdiff(colnames(train_df), var_to_predict)]
y_train <- train_df[, c("obs_id_value", var_to_predict)]
X_val <- val_df[, setdiff(colnames(train_df), var_to_predict)]
y_val <- val_df[, c("obs_id_value", var_to_predict)]
rm(train_df, val_df)
prop_noise_x <- 1
noise_level <- 30
q_noisy_var <- 1
if (prop_noise_x > 0) {
num_rows_to_add_noise <- ceiling(nrow(X_train) * prop_noise_x)
noise_level <- noise_level
if (dataset_actual == "Heart"){
df <- read.csv("./data/heart.csv")
tree <- rpart(HeartDisease~., data = df, control=rpart.control(minsplit=2, minbucket=1, maxdepth=10, cp=0, xval=0))
importance_scores <- tree$variable.importance
top_variables <- names(importance_scores[order(-importance_scores)])[1:q_noisy_var]
}
for (var_name in top_variables) {
if (is.numeric(X_train[[var_name]])) {
noise <- rnorm(num_rows_to_add_noise, mean = 0, sd = noise_level * sd(X_train[[var_name]]))
X_train[sample(nrow(X_train), num_rows_to_add_noise), var_name] <- X_train[sample(nrow(X_train), num_rows_to_add_noise), var_name] + noise
} else {
var_to_switch <- var_name
unique_levels <- unique(X_train[[var_to_switch]])
for (i in seq_len(num_rows_to_add_noise)) {
random_row <- sample(seq_len(nrow(X_train)), 1)
current_value <- X_train[random_row, var_to_switch]
replacement_value <- sample(setdiff(unique_levels, current_value), 1)
X_train[random_row, var_to_switch] <- replacement_value
}
}
}
}
names(importance_scores[order(-importance_scores)])[1:q_noisy_var]
X_train$ST_Slope
source("provided_functions_reentrega.R")
data <- load_df("./data/heart.csv", "Heart", "HeartDisease")
data_df <- data$data_df
dataset_actual <- data$dataset_name
var_to_predict <- data$var_to_predict
prop_val <- 0.25
val_index <- sample(1:nrow(data_df), ceiling(nrow(data_df) * prop_val))
train_df <- data_df[-val_index,]
train_df_anterior <- data_df[-val_index,]
val_df <- data_df[val_index,]
if ("obs_id_value" %in% colnames(train_df)) {
stop("obs_id_value is already a variable name in the data")
}
train_df$obs_id_value <- 1:nrow(train_df)
val_df$obs_id_value <- 1:nrow(val_df)
X_train <- train_df[, setdiff(colnames(train_df), var_to_predict)]
y_train <- train_df[, c("obs_id_value", var_to_predict)]
X_val <- val_df[, setdiff(colnames(train_df), var_to_predict)]
y_val <- val_df[, c("obs_id_value", var_to_predict)]
rm(train_df, val_df)
X_train$ST_Slope
q_noisy_var <- 5
names(importance_scores[order(-importance_scores)])[1:q_noisy_var]
knitr::include_graphics("./outputs/plots/exp_propio.jpg")
suppressWarnings(source("exp_propio.R"))
# Load the necessary libraries for data analysis and visualization
library(ggplot2)  # For creating plots
suppressPackageStartupMessages(library("dplyr"))  # For data manipulation
# Constants and global variables
PARALLELIZE <- TRUE # Set the option for parallelization of computations
N_THREADS <- 30     # Define the number of threads for parallel processing
N_BINS <- 10        # Define the number of bins for discretization
RERUN_EXP <- TRUE   # Set the option to rerun the experiment
# Load provided functions
source("provided_functions_reentrega.R")
#Set seed
set.seed(006396374)
#' Run an experiment to evaluate the performance of a predictive model under different conditions.
#'
#' @param datasets_to_pred A list of data frames, each containing a dataset to be predicted.
#' @param filepath The path to the file where the experiment results will be saved.
#' @return None (the experiment results are saved to a file).
#'
#' @details
#' This function iterates through the given datasets, imputation methods, and proportions
#' of missing data. For each combination, it configures the preprocessing options, performs
#' the experiment, and stores the results in a list. The list of results is then combined into
#' a single data frame, which is saved to the specified file.
#'
run_experiment <- function(datasets_to_pred, filepath) {
exp_results <- list()  # Store experiment results
i <- 1  # Initialize counter for experiment results
# Iterate through different dataset, imputation, and proportion of missing values combinations
for (dtp in datasets_to_pred) {
for (q in c(5,8,10,11)) {
for (noise_level in c(30)) {
print(c(dtp$dataset_name, q, noise_level))
# Configure preprocessing options based on imputation choice
preprocess_control <- list(
prop_NAs=0,
impute_NAs=FALSE,
treat_NAs_as_new_levels=FALSE,
do_ohe=FALSE,
discretize=FALSE,
n_bins=N_BINS,
ord_to_numeric=FALSE,
prop_switch_y=0,
prop_noise_x=1,
q_noisy_var=q,
dataset_actual=dtp$dataset_name,
noise_level=noise_level
)
# Perform the experiment for the current settings
if (PARALLELIZE == TRUE) {
res_tmp <- est_auc_across_depths(dtp, preprocess_control,
max_maxdepth=30, prop_val=0.25,
val_reps=30)
} else {
res_tmp <- est_auc_across_depths_no_par(dtp, preprocess_control,
max_maxdepth=30, prop_val=0.25,
val_reps=30)
}
res_tmp$q_noisy_var <- q
res_tmp$noise_level <- noise_level
exp_results[[i]] <- res_tmp
rm(res_tmp)  # Clean up temporary result
i <- i + 1  # Increment result counter
}
}
}
# Combine experiment results into a single data frame
exp_results <- do.call(rbind, exp_results)
# Save experiment results to a file
write.table(exp_results, filepath, row.names=FALSE, sep="\t")
}
#' Plot the results of the sample experiment using ggplot2.
#'
#' @param filename_exp_results The filename of the experiment results file.
#' @param filename_plot The filename to save the plot (e.g., "my_plot.png").
#' @param width The width of the plot in inches.
#' @param height The height of the plot in inches.
#' @return None (the plot is saved as an image file).
#'
#' @details
#' This function reads the experiment results, calculates the mean AUC values for different
#' experimental conditions, and generates a line plot using ggplot2. The plot displays the mean AUC
#' values against maximum tree depths, with different lines for different imputation methods and facets
#' for different datasets and proportions of missing data. The resulting plot is saved as the specified file.
#'
plot_exp_results <- function(filename_exp_results, filename_plot, width, height) {
# Load experiment results
exp_results <- read.table(filename_exp_results, header=TRUE, sep="\t")
exp_results$noise_level <- as.factor(exp_results$noise_level)
# Calculate max AUC values for different groups of experimental results
data_for_plot <- exp_results %>%
group_by(dataset_name, noise_level, q_noisy_var, maxdepth) %>%
summarize(mean_auc=mean(auc), .groups='drop')
# Create a ggplot object for the line plot
g <- ggplot(data_for_plot, aes(x=maxdepth, y=mean_auc, color=noise_level)) +
geom_line() +
theme_bw() +
ggtitle("Proportion of noisy X")+
xlab("Max tree depth") +
ylab("AUC (estimated through repeated validation)") +
facet_grid(dataset_name ~ q_noisy_var, scales="free_y") +
theme(legend.position="bottom",
panel.grid.major=element_blank(),
strip.background=element_blank(),
panel.border=element_rect(colour="black", fill=NA),
plot.title.position = 'plot',
plot.title = element_text(hjust=0.5, size=10))
# Save the plot to a file
ggsave(filename_plot, g, width=width, height=height)
print(g)
}
# Load the datasets
datasets_to_pred <- list(
#load_df("./data/CO2_Emissions_Transformado.csv", "CO2", "CO2.Emissions.gt.200gkm"),
load_df("./data/heart.csv", "Heart", "HeartDisease")
#load_df("./data/customer_churn.csv", "Churn", "churn")
)
# Run the experiment
if (RERUN_EXP ==  TRUE) {
run_experiment(datasets_to_pred, "./outputs/tables/exp_propio.txt")
}
